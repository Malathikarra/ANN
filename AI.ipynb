{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edefb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final v weights:\n",
      "[[ 0.02290479 -0.11740399]\n",
      " [-2.07507461 -1.88792315]]\n",
      "Final w weights:\n",
      "[[1.70955246 3.0049853 ]]\n",
      "Outputs for data:\n",
      "Input: [0 0], Predicted Output: [0.63815017], Actual Output: [0]\n",
      "Input: [0 1], Predicted Output: [0.59063319], Actual Output: [1]\n",
      "Input: [1 0], Predicted Output: [0.58470073], Actual Output: [1]\n",
      "Input: [1 1], Predicted Output: [0.2755684], Actual Output: [0]\n",
      "Epoch\tSquared Error\tAccuracy\n",
      "0\t0.5235859987249438\t0.4764140012750562\n",
      "1000\t0.28011240031009665\t0.7198875996899033\n",
      "2000\t0.2806785308733152\t0.7193214691266848\n",
      "3000\t0.2812805792867445\t0.7187194207132555\n",
      "4000\t0.28187476360441105\t0.718125236395589\n",
      "5000\t0.28237450411377757\t0.7176254958862225\n",
      "6000\t0.28265019930605423\t0.7173498006939458\n",
      "7000\t0.282739549254594\t0.717260450745406\n",
      "8000\t0.2828303546707535\t0.7171696453292464\n",
      "9000\t0.2785651419672041\t0.7214348580327958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Initializing weights with values sampled from a uniform distribution\n",
    "def initialize_weights(shape):\n",
    "    return np.random.uniform(-0.1, 0.1, shape)\n",
    "\n",
    "# Input data (XOR problem)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "# Target outputs\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Defining the number of units in each layer\n",
    "input_units = 2\n",
    "hidden_units = 2\n",
    "output_units = 1\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Initializing weights and biases\n",
    "v = initialize_weights((hidden_units, input_units))\n",
    "w = initialize_weights((output_units, hidden_units))\n",
    "b1 = np.zeros((hidden_units, 1))\n",
    "b2 = np.zeros((output_units, 1))\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "# Lists to store epoch, squared error, and accuracy\n",
    "epoch_list = []\n",
    "accuracy_list = []\n",
    "squared_error_list = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    squared_error_sum = 0\n",
    "    # Iterating through each input-output pair\n",
    "    for x, y_true in zip(X, Y):\n",
    "        x = x.reshape((1, 2))\n",
    "        y_true = y_true.reshape((1, 1))\n",
    "\n",
    "        # Forward pass\n",
    "        z = sigmoid(np.dot(v, x.T) + b1)\n",
    "        y_pred = np.dot(w, z) + b2\n",
    "\n",
    "        # Calculating squared error\n",
    "        squared_error = np.mean(np.square(y_true - y_pred))\n",
    "        squared_error_sum += squared_error\n",
    "\n",
    "        # Backpropagation\n",
    "        delta_w = learning_rate * np.dot((y_true - y_pred) * sigmoid_derivative(y_pred), z.T)\n",
    "        delta_v = learning_rate * np.dot(np.dot(w.T, (y_true - y_pred) * sigmoid_derivative(y_pred)) * sigmoid_derivative(z), x)\n",
    "\n",
    "        # Updating weights and biases\n",
    "        w += delta_w\n",
    "        v += delta_v\n",
    "        b2 += learning_rate * (y_true - y_pred)\n",
    "        b1 += learning_rate * np.dot(w.T, (y_true - y_pred) * sigmoid_derivative(y_pred))\n",
    "\n",
    "    # Calculating accuracy and store values\n",
    "    if epoch % 1000 == 0:\n",
    "        epoch_list.append(epoch)\n",
    "        accuracy = 1 - squared_error_sum / len(X)\n",
    "        accuracy_list.append(accuracy)\n",
    "        squared_error_list.append(squared_error_sum / len(X))\n",
    "\n",
    "# Printing final weights and biases\n",
    "print(\"Final v weights:\")\n",
    "print(v)\n",
    "print(\"Final w weights:\")\n",
    "print(w)\n",
    "\n",
    "# Printing outputs for each input\n",
    "print(\"Outputs for data:\")\n",
    "for x, y_true in zip(X, Y):\n",
    "    x = x.reshape((1, 2))\n",
    "    z = sigmoid(np.dot(v, x.T) + b1)\n",
    "    y_pred = np.dot(w, z) + b2\n",
    "    print(f\"Input: {x.flatten()}, Predicted Output: {y_pred.flatten()}, Actual Output: {y_true}\")\n",
    "\n",
    "# Printing epoch, squared error, and accuracy\n",
    "print(\"Epoch\\tSquared Error\\tAccuracy\")\n",
    "for i in range(len(epoch_list)):\n",
    "    print(f\"{epoch_list[i]}\\t{squared_error_list[i]}\\t{accuracy_list[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
